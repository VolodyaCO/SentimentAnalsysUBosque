{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import preprocessor as p  # módulo para limpiar tweets\n",
    "from pymongo import MongoClient  # módulo para crear un cliente de la base de datos de mongo\n",
    "import language_check  # módulo para corregir los tweets\n",
    "from nltk.tokenize import TweetTokenizer  # módulo para tokenizar los tweets\n",
    "import unicodedata  # módulo para tratar caracteres unicode\n",
    "from nltk.corpus import stopwords  # lista de palabras basura\n",
    "from nltk import FreqDist\n",
    "p.set_options(p.OPT.URL)  # hace que preprocessor solo borre las URL dentro de los tweet\n",
    "tknzr = TweetTokenizer()  # selecciona el tokenizador para tweets\n",
    "tool = language_check.LanguageTool('es')  # trabajador de language_check para correjir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "    \"\"\"\n",
    "    Quita los acentos para que el tokenizador de tweets no parta las palabras con tildes en 2.\n",
    "    \"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def remove_stopwords(sentence, language):\n",
    "    \"\"\"\n",
    "    Dada una frase, devuelve la frase tokenizada y sin palabras basura\n",
    "    \"\"\"\n",
    "    return [ token for token in tknzr.tokenize(strip_accents(sentence)) if token.lower() not in stopwords.words(language) ]\n",
    "\n",
    "def correct_word(word):\n",
    "    \"\"\"\n",
    "    Corrije las palabras si es necesario\n",
    "    \"\"\"\n",
    "    matches = tool.check(word)\n",
    "    return language_check.correct(word, matches)\n",
    "\n",
    "def clean_correct_tokenize(text):\n",
    "    \"\"\"\n",
    "    Hace todo el procedimiento de limpiar, correjir, tokenizar. La lematización se hará en otro \n",
    "    programa porque requiere Python2.\n",
    "    \"\"\"\n",
    "    clean = p.clean(text)\n",
    "    matches = tool.check(text)\n",
    "    corrected = language_check.correct(text, matches).lower()\n",
    "    no_stop_words = remove_stopwords(corrected, 'spanish')\n",
    "    tokens = [correct_word(word).lower() for word in no_stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68017\n",
      "1000 tuits visitados\n",
      "2000 tuits visitados\n",
      "3000 tuits visitados\n",
      "4000 tuits visitados\n",
      "5000 tuits visitados\n",
      "6000 tuits visitados\n",
      "7000 tuits visitados\n",
      "8000 tuits visitados\n",
      "9000 tuits visitados\n",
      "10000 tuits visitados\n",
      "11000 tuits visitados\n",
      "12000 tuits visitados\n",
      "13000 tuits visitados\n",
      "14000 tuits visitados\n",
      "15000 tuits visitados\n",
      "16000 tuits visitados\n",
      "17000 tuits visitados\n",
      "18000 tuits visitados\n",
      "19000 tuits visitados\n",
      "20000 tuits visitados\n",
      "21000 tuits visitados\n",
      "22000 tuits visitados\n",
      "23000 tuits visitados\n",
      "24000 tuits visitados\n",
      "25000 tuits visitados\n",
      "26000 tuits visitados\n",
      "27000 tuits visitados\n",
      "28000 tuits visitados\n",
      "29000 tuits visitados\n",
      "30000 tuits visitados\n",
      "31000 tuits visitados\n",
      "32000 tuits visitados\n",
      "33000 tuits visitados\n",
      "34000 tuits visitados\n",
      "35000 tuits visitados\n",
      "36000 tuits visitados\n",
      "37000 tuits visitados\n",
      "38000 tuits visitados\n",
      "39000 tuits visitados\n",
      "40000 tuits visitados\n",
      "41000 tuits visitados\n",
      "42000 tuits visitados\n",
      "43000 tuits visitados\n",
      "44000 tuits visitados\n",
      "45000 tuits visitados\n",
      "46000 tuits visitados\n",
      "47000 tuits visitados\n",
      "48000 tuits visitados\n",
      "49000 tuits visitados\n",
      "50000 tuits visitados\n",
      "51000 tuits visitados\n",
      "52000 tuits visitados\n",
      "53000 tuits visitados\n",
      "54000 tuits visitados\n",
      "55000 tuits visitados\n",
      "56000 tuits visitados\n",
      "57000 tuits visitados\n",
      "58000 tuits visitados\n",
      "59000 tuits visitados\n",
      "60000 tuits visitados\n",
      "61000 tuits visitados\n",
      "62000 tuits visitados\n",
      "63000 tuits visitados\n",
      "64000 tuits visitados\n",
      "65000 tuits visitados\n",
      "66000 tuits visitados\n",
      "67000 tuits visitados\n",
      "68000 tuits visitados\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client['tweets']\n",
    "col = db['training']\n",
    "\n",
    "lens = []  # longitud en caracteres de tweets\n",
    "toklens = []  # longitud en número de tokens de tweets\n",
    "vocab = []  # lista que contiene todo el vocabulario\n",
    "\n",
    "i = 0\n",
    "print(col.find({}).count())\n",
    "for tw in col.find():  # itera sobre los tweets guardados en la base de datos\n",
    "    i += 1\n",
    "    if i%1000==0:\n",
    "        print(i, \"tuits visitados\")\n",
    "    content = tw['content']  # extrae el contenido del tweet\n",
    "    lens.append(len(content))  # añade la longitud en caracteres a la lista lens\n",
    "    tokens = clean_correct_tokenize(content)  # crea los tokens del contenido\n",
    "    col.update_one({\"_id\": tw[\"_id\"]}, {'$set': {\"tokens\": tokens}})\n",
    "    toklens.append(len(tokens))  # añade la cantidad de tokens a la lista toklens\n",
    "    for tok in tokens:  # guarda los tokens de cada tweet en el vocabulario\n",
    "        vocab.append(tok)\n",
    "fdist = FreqDist(vocab)\n",
    "vocab = list(set(vocab))  # hace que cada palabra aparezca una sola vez en el vocabulario\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "with open(os.path.join('pickles', 'char_tw_lens.p'), \"wb\") as f:\n",
    "    pickle.dump(lens, f)\n",
    "\n",
    "with open(os.path.join('pickles', 'token_tw_lens.p'), \"wb\") as f:\n",
    "    pickle.dump(toklens, f)\n",
    "    \n",
    "with open(os.path.join('pickles', 'non_lema_vocab.p'), \"wb\") as f:\n",
    "    pickle.dump(vocab, f, protocol=2)\n",
    "    \n",
    "with open(os.path.join('pickles', 'vocab_dist.p'), \"wb\") as f:\n",
    "    pickle.dump(fdist, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CursorNotFound",
     "evalue": "Cursor not found, cursor id: 25601201930",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCursorNotFound\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f7c3bb9a0109>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rae'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"ok\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"defs\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdefs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"defs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mall_tok_defs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vladimir/anaconda3/lib/python3.5/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1112\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[0m_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_refresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                 return _db._fix_outgoing(self.__data.popleft(),\n",
      "\u001b[1;32m/home/vladimir/anaconda3/lib/python3.5/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m_refresh\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1054\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__codec_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                                              self.__max_await_time_ms))\n\u001b[0m\u001b[0;32m   1057\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Cursor id is zero nothing else to return\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vladimir/anaconda3/lib/python3.5/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36m__send_message\u001b[1;34m(self, operation)\u001b[0m\n\u001b[0;32m    924\u001b[0m             doc = helpers._unpack_response(response=data,\n\u001b[0;32m    925\u001b[0m                                            \u001b[0mcursor_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m                                            codec_options=self.__codec_options)\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfrom_command\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m                 \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_command_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vladimir/anaconda3/lib/python3.5/site-packages/pymongo/helpers.py\u001b[0m in \u001b[0;36m_unpack_response\u001b[1;34m(response, cursor_id, codec_options)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Cursor not found, cursor id: %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcursor_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0merrobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"ok\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"errmsg\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"code\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mCursorNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mresponse_flag\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0merror_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBSON\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCursorNotFound\u001b[0m: Cursor not found, cursor id: 25601201930"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client['tweets']\n",
    "col = db['rae']\n",
    "\n",
    "for w in col.find({\"ok\":1}, {\"defs\":1}):\n",
    "    defs = w[\"defs\"]\n",
    "    all_tok_defs = []\n",
    "    for df in defs:\n",
    "        tokens = clean_correct_tokenize(df)\n",
    "        all_tok_defs.append(tokens)\n",
    "    col.update_one({\"_id\": w[\"_id\"]}, {'$set': {\"tokens\": all_tok_defs}})\n",
    "\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
